{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "conn_str = f'mysql+pymysql://fnbrasil:{password}@localhost:3307/fnbr_db'\n",
    "\n",
    "engine = create_engine(conn_str, pool_recycle=3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_frm = pd.read_sql('''\n",
    "    select f.idFrame, e.name, e.description, tf.frameTop\n",
    "    from view_frame f\n",
    "    join entry e on e.entry = f.entry\n",
    "    left join topframe tf on tf.frameBase = f.entry and tf.frameTop in ('frm_event', 'frm_entity', 'frm_attributes')\n",
    "    where e.idLanguage = 2 and exists(\n",
    "        select 1\n",
    "        from view_relation r\n",
    "        join domain d on d.`idEntity`  = r.idEntity2\n",
    "        where r.idEntity1 = f.`idEntity` and d.entry ='dom_framenet' \n",
    "    );\n",
    "''', engine).set_index(\"idFrame\", drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = pd.read_sql('''\n",
    "    select fe.idFrameElement, fe.typeEntry, e.name, e.description, fe.idFrame\n",
    "    from view_frameelement fe\n",
    "    join entry e on e.entry = fe.entry\n",
    "    where idLanguage = 2;\n",
    "''', engine).set_index(\"idFrameElement\", drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lu = pd.read_sql('''\n",
    "    select lu.idLU, lu.name, lu.senseDescription, lu.idFrame \n",
    "    from view_lu lu\n",
    "    where lu.idLanguage = 2;\n",
    "''', engine).set_index(\"idLU\", drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lu_pt = pd.read_sql('''\n",
    "    select lu.idLU, lu.name, lu.senseDescription, lu.idFrame \n",
    "    from view_lu lu\n",
    "    where lu.idLanguage = 1;\n",
    "''', engine).set_index(\"idLU\", drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rel = pd.read_sql('''\n",
    "    select r.entry, f1.idFrame as 'idFrame1', f2.idFrame as 'idFrame2'\n",
    "    from entityrelation e\n",
    "    join relationtype r on r.idRelationType = e.idRelationType  \n",
    "    join frame f1 on e.idEntity1 = f1.`idEntity` \n",
    "    join frame f2 on e.idEntity2 = f2.`idEntity`;\n",
    "''', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_fnp = pd.read_csv(os.path.join('FN+', 'all-data', 'frameindexLU'),\n",
    "                     sep='\\t', header=None, usecols=[2, 3], names=['frameName', 'luName'])\n",
    "\n",
    "df_fnp = df_fnp.merge(df_frm, how='left', left_on='frameName', right_on='name')[['idFrame', 'luName']]\n",
    "df_fnp = df_fnp[~df_fnp['idFrame'].isnull()]\n",
    "\n",
    "df_fnp['idFrame'] = df_fnp['idFrame'].astype('int')\n",
    "df_fnp['luName'] = df_fnp['luName'].apply(lambda l: l.split('.')[0])\n",
    "\n",
    "fnp = df_fnp.groupby('idFrame')['luName'].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "df_inh = df_rel[df_rel[\"entry\"] == \"rel_inheritance\"]\n",
    "\n",
    "fn = nx.DiGraph()\n",
    "fn.add_nodes_from(pd.concat([df_inh['idFrame1'], df_inh['idFrame2']]).unique())\n",
    "fn.add_edges_from([(j, i) for i, j in zip(df_inh['idFrame1'], df_inh['idFrame2'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def clean_def(text):\n",
    "    text = re.sub(r'\\<ex\\>.*', '', text, flags=re.DOTALL)\n",
    "    text = text.replace('<def-root>', '')\n",
    "    text = text.replace('</def-root>', '')\n",
    "    def_root = ET.fromstring('<def>' + text + '</def>')\n",
    "    def_str = def_root.text if def_root.text is not None else \"\"\n",
    "    for child in def_root:\n",
    "        if child.tag == \"ex\":\n",
    "            break\n",
    "        if child.text is not None:\n",
    "            def_str += child.text\n",
    "        if child.tail is not None:\n",
    "            def_str += child.tail\n",
    "\n",
    "    return def_str.strip()\n",
    "\n",
    "# Remove \"meta\"\n",
    "df_frm[\"description\"] = df_frm[\"description\"].apply(clean_def)\n",
    "df_frm[\"description\"] = df_frm[\"description\"].str.replace('\\s+', r' ', regex=True)\n",
    "df_frm[\"description\"] = df_frm[\"description\"].str.replace('#(\\w+)', r'\\1', regex=True)\n",
    "\n",
    "df_fe[\"description\"] = df_fe[\"description\"].apply(clean_def)\n",
    "df_fe[\"description\"] = df_fe[\"description\"].str.replace('\\s+', r' ', regex=True)\n",
    "df_fe[\"description\"] = df_fe[\"description\"].str.replace('#(\\w+)', r'\\1', regex=True)\n",
    "\n",
    "df_lu[\"senseDescription\"] = df_lu[\"senseDescription\"].str.replace('FN: ', '')\n",
    "df_lu[\"senseDescription\"] = df_lu[\"senseDescription\"].str.strip()\n",
    "df_lu_pt[\"senseDescription\"] = df_lu_pt[\"senseDescription\"].str.replace('FN: ', '')\n",
    "df_lu_pt[\"senseDescription\"] = df_lu_pt[\"senseDescription\"].str.strip()\n",
    "\n",
    "# Other\n",
    "df_lu[\"name\"] = df_lu[\"name\"].str.replace('_', ' ')\n",
    "df_lu[\"name\"] = df_lu[\"name\"].str.replace('[', '(', regex=False)\n",
    "df_lu[\"name\"] = df_lu[\"name\"].str.replace(']', ')', regex=False)\n",
    "df_lu_pt[\"name\"] = df_lu_pt[\"name\"].str.replace('_', ' ')\n",
    "df_lu_pt[\"name\"] = df_lu_pt[\"name\"].str.replace('[', '(', regex=False)\n",
    "df_lu_pt[\"name\"] = df_lu_pt[\"name\"].str.replace(']', ')', regex=False)\n",
    "\n",
    "df_frm['name'] = df_frm['name'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample FrameNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered =  df_frm[df_frm['idFrame'].isin(fnp)]\n",
    "\n",
    "frm_event = set(df_filtered[df_filtered['frameTop'] == 'frm_event']['idFrame'])\n",
    "frm_entity = set(df_filtered[df_filtered['frameTop'] == 'frm_entity']['idFrame'])\n",
    "frm_attribute = set(df_filtered[df_filtered['frameTop'] == 'frm_attributes']['idFrame'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corefe = df_fe[df_fe['typeEntry'].isin(['cty_core', 'cty_core-unexpressed'])]\n",
    "\n",
    "frm_event_fe_count = df_corefe[df_corefe['idFrame'].isin(frm_event)].groupby('idFrame').count()['idFrameElement']\n",
    "frm_entity_fe_count = df_corefe[df_corefe['idFrame'].isin(frm_entity)].groupby('idFrame').count()['idFrameElement']\n",
    "frm_attribute_fe_count = df_corefe[df_corefe['idFrame'].isin(frm_attribute)].groupby('idFrame').count()['idFrameElement']\n",
    "\n",
    "frm_event_lu_count = df_lu[df_lu['idFrame'].isin(frm_event)].groupby('idFrame').count()['idLU']\n",
    "frm_entity_lu_count = df_lu[df_lu['idFrame'].isin(frm_entity)].groupby('idFrame').count()['idLU']\n",
    "frm_attribute_lu_count = df_lu[df_lu['idFrame'].isin(frm_attribute)].groupby('idFrame').count()['idLU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frm_splits(fe_count, lu_count):\n",
    "    lower_fe = fe_count[fe_count <= fe_count.quantile(.25)]\n",
    "    upper_fe = fe_count[fe_count >= fe_count.quantile(.75)]\n",
    "    \n",
    "    lower_lu = lu_count[lu_count <= lu_count.quantile(.25)]\n",
    "    upper_lu = lu_count[lu_count >= lu_count.quantile(.75)]\n",
    "    \n",
    "    return (\n",
    "        lower_fe.index.intersection(lower_lu.index),\n",
    "        lower_fe.index.intersection(upper_lu.index),\n",
    "        upper_fe.index.intersection(lower_lu.index),\n",
    "        upper_fe.index.intersection(upper_lu.index)\n",
    "    )\n",
    "\n",
    "def print_stats(splits):\n",
    "    print('Low FE x Low LU:', len(splits[0]))\n",
    "    print('Low FE x Upp LU:', len(splits[1]))\n",
    "    print('Upp FE x Low LU:', len(splits[2]))\n",
    "    print('Upp FE x Upp LU:', len(splits[3]))\n",
    "\n",
    "event_splits = get_frm_splits(frm_event_fe_count, frm_event_lu_count)\n",
    "entity_splits = get_frm_splits(frm_entity_fe_count, frm_entity_lu_count)\n",
    "attribute_splits = get_frm_splits(frm_attribute_fe_count, frm_attribute_lu_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This are the utility functions used by the prompt generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from random import random\n",
    "from collections import OrderedDict\n",
    "from networkx import all_neighbors\n",
    "\n",
    "POS = {\n",
    "    \"v\": \"verb\",\n",
    "    \"a\": \"adjective\",\n",
    "    \"n\": \"noun\",\n",
    "    \"adv\": \"adverb\",\n",
    "    \"pron\": \"pronoun\",\n",
    "    \"prep\": \"preposition\",\n",
    "    \"idio\": \"idiomatic expression\"\n",
    "}\n",
    "\n",
    "\n",
    "def get_prompt_data(idFrame):\n",
    "    frm = df_frm.loc[idFrame]\n",
    "    core_fes = df_fe[(df_fe[\"idFrame\"] == idFrame) & (df_fe[\"typeEntry\"] == \"cty_core\")]\n",
    "    unexp_fes = df_fe[(df_fe[\"idFrame\"] == idFrame) & (df_fe[\"typeEntry\"] == \"cty_core-unexpressed\")]\n",
    "    lus = df_lu[df_lu[\"idFrame\"] == idFrame]\n",
    "    \n",
    "    core_fes = core_fes[[\"name\", \"description\"]].to_dict('records')\n",
    "    unexp_fes = unexp_fes[[\"name\", \"description\"]].to_dict('records')\n",
    "    lus = lus[[\"name\", \"senseDescription\"]].to_dict('records')\n",
    "    \n",
    "    return {\n",
    "        \"id\": frm[\"idFrame\"],\n",
    "        \"name\": frm[\"name\"],\n",
    "        \"description\": frm[\"description\"],\n",
    "        \"core_fes\": core_fes,\n",
    "        \"unexp_fes\": unexp_fes,\n",
    "        \"lus\": lus\n",
    "    }\n",
    "\n",
    "\n",
    "def fmt_entity(text):\n",
    "    return text.replace('_', ' ')\n",
    "\n",
    "def fmt_definition(text):\n",
    "    return text.strip()[:-1] if text.strip()[-1] == '.' else text\n",
    "\n",
    "def to_comma(arr):\n",
    "    if len(arr) == 1:\n",
    "        return f'\"{fmt_entity(arr[0])}\"'\n",
    "    \n",
    "    if len(arr) == 2:\n",
    "        return f'\"{fmt_entity(arr[0])}\" and \"{fmt_entity(arr[-1])}\"'\n",
    "    \n",
    "    other = ''.join([f', \"{fmt_entity(w)}\"' for w in arr[1:-1]])\n",
    "\n",
    "    return f'\"{fmt_entity(arr[0])}\"{other} and \"{fmt_entity(arr[-1])}\"'\n",
    "\n",
    "\n",
    "def pos_counts(lus):\n",
    "    counts = OrderedDict()\n",
    "    \n",
    "    for lu in lus:\n",
    "        pos = lu[1]\n",
    "        if pos in counts:\n",
    "            counts[pos] += 1\n",
    "        else:\n",
    "            counts[pos] = 1\n",
    "    \n",
    "    return counts\n",
    "\n",
    "\n",
    "def pos_names(counts):\n",
    "    pos_dict = POS.copy()\n",
    "    \n",
    "    for k, v in counts.items():\n",
    "        if v > 1:\n",
    "            # add plural\n",
    "            pos_dict[k] += 's'\n",
    "            \n",
    "    return pos_dict\n",
    "\n",
    "\n",
    "def fe_text(core_fes, unexp_fes = []):\n",
    "    core_fes = [f[\"name\"] for f in core_fes]\n",
    "    unexp_fes = [f[\"name\"] for f in unexp_fes]\n",
    "    \n",
    "    prompt = ''\n",
    "    \n",
    "    if len(core_fes) == 1:\n",
    "        prompt += f' The core frame element in this frame is \"{fmt_entity(core_fes[0])}\".'\n",
    "    else:\n",
    "        prompt += f' Core frame elements in this frame are {to_comma(core_fes)}.'\n",
    "    \n",
    "    if len(unexp_fes) == 1:\n",
    "        prompt += f' The core unexpressed frame element in this frame is \"{fmt_entity(unexp_fes[0])}\".'\n",
    "    elif len(unexp_fes) > 1:\n",
    "        prompt += f' Core unexpressed frame elements in this frame are {to_comma(unexp_fes)}.'\n",
    "        \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def lu_text(lus):\n",
    "    lus = sorted((lu[\"name\"].split('.') for lu in lus), key=lambda lu: lu[1])\n",
    "    \n",
    "    if len(lus) == 1:\n",
    "        return f' This frame is evoked by the {POS[lus[0][1]]} \"{lus[0][0]}\"'\n",
    "    else:\n",
    "        pos = lus[0][1]\n",
    "        pos_i = 1\n",
    "        counts = pos_counts(lus)\n",
    "        names = pos_names(counts)\n",
    "        order = list(counts.keys())\n",
    "        text = f' Words evoking this frame are the {names[pos]} \"{lus[0][0]}\"'\n",
    "        \n",
    "        for i, lu in enumerate(lus[1:]):\n",
    "            if lu[1] == pos:\n",
    "                pos_i += 1\n",
    "                last = i+2 == len(lus) or pos_i == counts[pos]\n",
    "                sep = ' and' if last else ','\n",
    "                text += f'{sep} \"{lu[0]}\"'\n",
    "            else:\n",
    "                pos = lu[1]\n",
    "                pos_i = 0\n",
    "                sep = ' and' if pos == order[-1] else ','\n",
    "                text += f'{sep} the {names[pos]} \"{lu[0]}\"'\n",
    "        \n",
    "        return text + '.'\n",
    "\n",
    "\n",
    "def random_child_frm(anchor, graph):\n",
    "    # Get \"neighbors\" with the correct direction\n",
    "    options = [n for n in all_neighbors(graph, anchor) if graph.has_edge(n, anchor)]\n",
    "    return options[math.floor(random() * len(options))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def prompt_suggest_lus(data):\n",
    "    # Frame definition\n",
    "    prompt = f'The semantic frame for \"{fmt_entity(data[\"name\"])}\" is defined as follows:'\n",
    "    prompt += f' \"{fmt_definition(data[\"description\"])}\".'\n",
    "    \n",
    "    # FEs\n",
    "    prompt += fe_text(data[\"core_fes\"], data[\"unexp_fes\"])\n",
    "    \n",
    "    # FE definitions\n",
    "    for fe in data[\"core_fes\"]:\n",
    "        prompt += f' {fmt_definition(fe[\"name\"])}: {fmt_definition(fe[\"description\"])}.'\n",
    "    for fe in data[\"unexp_fes\"]:\n",
    "        prompt += f' {fmt_definition(fe[\"name\"])}: {fmt_definition(fe[\"description\"])}.'\n",
    "        \n",
    "    # LU\n",
    "    prompt += lu_text(data[\"lus\"])\n",
    "    \n",
    "    # Request part\n",
    "    prompt += f' Please propose 10 additional words that evoke the \"{fmt_entity(data[\"name\"])}\" semantic frame.'\n",
    "    prompt += f' Present them as a JSON array.'\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def prompt_create_from_lus(data, new_lus):\n",
    "    # Frame definition\n",
    "    prompt = f'The semantic frame for \"{fmt_entity(data[\"name\"])}\" is defined as follows:'\n",
    "    prompt += f' \"{fmt_definition(data[\"description\"])}\".'\n",
    "    \n",
    "    # FEs\n",
    "    fes = [f[\"name\"] for f in data[\"core_fes\"]]\n",
    "    \n",
    "    if len(fes) == 1:\n",
    "        prompt += f' The semantic frame for \"{fmt_entity(data[\"name\"])}\" has one core frame element:'\n",
    "        prompt += f' \"{fmt_entity(fes[0])}\".'\n",
    "    else:\n",
    "        prompt += f' The semantic frame for \"{fmt_entity(data[\"name\"])}\" has {len(fes)} core elements:'\n",
    "        prompt += f' {to_comma(fes)}.'\n",
    "\n",
    "    for fe in data[\"core_fes\"]:\n",
    "        prompt += f' The definition of the \"{fmt_entity(fe[\"name\"])}\" frame element is as follows:'\n",
    "        prompt += f' \"{fmt_definition(fe[\"description\"])}\".'\n",
    "\n",
    "    # LUs\n",
    "    prompt += lu_text(data[\"lus\"])\n",
    "    \n",
    "    # Request part\n",
    "    prompt += f' First, propose a semantic frame evoked by words such as {to_comma(new_lus)}.'\n",
    "    prompt += f' Second, please propose semantic frames for other kinds of \"{fmt_entity(data[\"name\"])}\".'\n",
    "    prompt += ' Present them as table in which columns are \"Frame Name\", \"Frame Definition\", \"Frame Elements\", \"Frame Element Definition\" and \"Words evoking the frame\".'\n",
    "        \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def prompt_create_from_inheritance(data, child_data):\n",
    "    # Frame definition\n",
    "    prompt = f'There is a semantic frame for \"{fmt_entity(data[\"name\"])}\", whose definition is as follows:'\n",
    "    prompt += f' \"{fmt_definition(data[\"description\"])}\".'\n",
    "    \n",
    "    # FEs\n",
    "    prompt += fe_text(data[\"core_fes\"], data[\"unexp_fes\"])\n",
    "    \n",
    "    # Child frame\n",
    "    prompt += f' The \"{fmt_entity(child_data[\"name\"])}\" frame inherits the \"{fmt_entity(data[\"name\"])}\" frame.'\n",
    "    \n",
    "    # Child FEs\n",
    "    prompt += fe_text(data[\"core_fes\"])\n",
    "    \n",
    "    # Child LUs\n",
    "    prompt += lu_text(child_data[\"lus\"])\n",
    "    \n",
    "    # Request part\n",
    "    prompt += f' Please propose other semantic frames inheriting the \"{fmt_entity(data[\"name\"])}\" frame.'\n",
    "    prompt += ' Present them as a table in which columns are \"Frame Name\", \"Frame Definition\", \"Frame Elements\", \"Frame Element Definition\" and \"Words evoking the frame\".'\n",
    "        \n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt for new LUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_split_prompt(splits, random=True):\n",
    "    full_prompt = ''\n",
    "    \n",
    "    for i, split in enumerate(splits):\n",
    "        full_prompt += \"=================================================\\n\"\n",
    "        full_prompt += f'---------------      SPLIT {i}      ---------------\\n'\n",
    "        full_prompt += \"=================================================\\n\"\n",
    "        \n",
    "        if random:\n",
    "            frame_ids = np.random.choice(split, size=5, replace=False)\n",
    "        else:\n",
    "            frame_ids = split\n",
    "        \n",
    "        for idFrame in frame_ids:\n",
    "            full_prompt += f'{str(idFrame)} - {prompt_suggest_lus(get_prompt_data(idFrame))}'\n",
    "            full_prompt += '\\n\\n\\n'\n",
    "\n",
    "    return full_prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =generate_split_prompt(attribute_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_splits = (\n",
    "    [318, 220, 46, 731, 1015],\n",
    "    [345, 1000, 453, 838, 326],\n",
    "    [882, 959, 685, 725, 601],\n",
    "    [342, 74, 332, 106, 125],\n",
    ")\n",
    "\n",
    "prompt = generate_split_prompt(attribute_splits, random=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idFrame</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>frameTop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idFrame</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>249</td>\n",
       "      <td>Avoiding</td>\n",
       "      <td>An Agent avoids an Undesirable_situation under...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         idFrame      name                                        description  \\\n",
       "idFrame                                                                         \n",
       "249          249  Avoiding  An Agent avoids an Undesirable_situation under...   \n",
       "\n",
       "        frameTop  \n",
       "idFrame           \n",
       "249         None  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_frm[df_frm[\"name\"].str.contains(\"Avoidin\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(prompt_create_from_lus(get_prompt_data(226), [\"god\", \"saint\", \"deity\", \"goddess\"]))\n",
    "# print(prompt_create_from_inheritance(get_prompt_data(178), get_prompt_data(random_child_frm(178, fn))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open(os.path.join('ChatGPT', 'event_en.json')) as fp:\n",
    "    event_lus = json.load(fp)\n",
    "    \n",
    "with open(os.path.join('ChatGPT', 'entity_en.json')) as fp:\n",
    "    entity_lus = json.load(fp)\n",
    "    \n",
    "with open(os.path.join('ChatGPT', 'attribute_en.json')) as fp:\n",
    "    attribute_lus = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FrameNet Br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lu(text):\n",
    "    return text.lower().split('.')[0]\n",
    "\n",
    "fnbr_merged = df_lu_pt.merge(df_frm.reset_index(drop=True), on='idFrame')[['name_x', 'idFrame']]\n",
    "fnbr_merged['name_x'] = fnbr_merged['name_x'].apply(clean_lu)\n",
    "\n",
    "fnbr = fnbr_merged.groupby('idFrame')['name_x'].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(type_lus):\n",
    "    return pd.DataFrame.from_records([\n",
    "        { \"idFrame\": int(idFrame), \"lu\": clean_lu(lu), \"split\": split }\n",
    "        for split, frames in type_lus.items()\n",
    "        for idFrame, lus in frames.items()\n",
    "        for lu in lus\n",
    "    ])\n",
    "\n",
    "\n",
    "def is_in_fnp(row):\n",
    "    if row['idFrame'] not in fnp:\n",
    "        return False\n",
    "    \n",
    "    return row['lu'] in fnp[row['idFrame']]\n",
    "\n",
    "def is_in_fnbr(row):\n",
    "    if row['idFrame'] not in fnbr:\n",
    "        return False\n",
    "    \n",
    "    return row['lu'] in fnbr[row['idFrame']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_df(attribute_lus)\n",
    "\n",
    "df['split'] = df['split'].str.replace('split-', '')\n",
    "df['FN+?'] = df.apply(is_in_fnp, axis='columns')\n",
    "df = df.merge(df_frm.reset_index(drop=True), on='idFrame')\n",
    "\n",
    "df[['name', 'lu', 'split', 'FN+?']].to_csv('lus.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
