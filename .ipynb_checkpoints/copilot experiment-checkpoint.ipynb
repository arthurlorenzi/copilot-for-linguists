{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up basic connection with MariaDB server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "user = \"fnbrasil\" # getpass.getuser()\n",
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OssracF1982'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "conn_str = f'mysql+pymysql://{user}:{password}@localhost:3307/fnbr_db'\n",
    "engine = create_engine(conn_str, pool_recycle=3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load frames, frame elements, lexical units (in Portuguese and English) and frame relations from FrameNet Brasil's database into different DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "frames = pd.read_sql('''\n",
    "    select f.idFrame, e.name, e.description, tf.frameTop\n",
    "    from view_frame f\n",
    "    join entry e on e.entry = f.entry\n",
    "    left join topframe tf on tf.frameBase = f.entry and tf.frameTop in ('frm_event', 'frm_entity', 'frm_attributes')\n",
    "    where e.idLanguage = 2 and exists(\n",
    "        select 1\n",
    "        from view_relation r\n",
    "        join domain d on d.`idEntity`  = r.idEntity2\n",
    "        where r.idEntity1 = f.`idEntity` and d.entry ='dom_framenet' \n",
    "    );\n",
    "''', engine).set_index(\"idFrame\", drop=False)\n",
    "\n",
    "\n",
    "fes = pd.read_sql('''\n",
    "    select fe.idFrameElement, fe.typeEntry, e.name, e.description, fe.idFrame\n",
    "    from view_frameelement fe\n",
    "    join entry e on e.entry = fe.entry\n",
    "    where idLanguage = 2;\n",
    "''', engine).set_index(\"idFrameElement\", drop=False)\n",
    "\n",
    "\n",
    "lus_en = pd.read_sql('''\n",
    "    select lu.idLU, lu.name, lu.senseDescription, lu.idFrame \n",
    "    from view_lu lu\n",
    "    where lu.idLanguage = 2;\n",
    "''', engine).set_index(\"idLU\", drop=False)\n",
    "\n",
    "\n",
    "lus_pt = pd.read_sql('''\n",
    "    select lu.idLU, lu.name, lu.senseDescription, lu.idFrame \n",
    "    from view_lu lu\n",
    "    where lu.idLanguage = 1;\n",
    "''', engine).set_index(\"idLU\", drop=False)\n",
    "\n",
    "\n",
    "frame_relations = pd.read_sql('''\n",
    "    select r.entry, f1.idFrame as 'idFrame1', f2.idFrame as 'idFrame2'\n",
    "    from entityrelation e\n",
    "    join relationtype r on r.idRelationType = e.idRelationType  \n",
    "    join frame f1 on e.idEntity1 = f1.`idEntity` \n",
    "    join frame f2 on e.idEntity2 = f2.`idEntity`;\n",
    "''', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load FrameNet+ from the local file system into a dataframe, then convert it into a **Dict[int, set[str]]**, where int is the numerical frame id and the set represents the LUs included by FrameNet+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "fn_plus = pd.read_csv(os.path.join('FN+', 'all-data', 'frameindexLU'),\n",
    "                     sep='\\t', header=None, usecols=[2, 3], names=['frameName', 'luName'])\n",
    "\n",
    "# Merge with frame DataFrame\n",
    "fn_plus = fn_plus.merge(frames, how='left', left_on='frameName', right_on='name')[['idFrame', 'luName']]\n",
    "# Remove those that were not found in the current database\n",
    "fn_plus = fn_plus[~fn_plus['idFrame'].isnull()]\n",
    "\n",
    "# Remove POS because we're not going to ask that from the AI assistants\n",
    "fn_plus['idFrame'] = fn_plus['idFrame'].astype('int')\n",
    "fn_plus['luName'] = fn_plus['luName'].apply(lambda l: l.split('.')[0])\n",
    "\n",
    "fn_plus = fn_plus.groupby('idFrame')['luName'].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a similar dict but with the FrameNet Brasil LUs instead, to evaluate the other experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnbr = lus_pt.merge(frames.reset_index(drop=True), on=\"idFrame\")[[\"name_x\", \"idFrame\"]]\n",
    "fnbr[\"name_x\"] = fnbr[\"name_x\"].apply(lambda l: l.lower().split('.')[0])\n",
    "\n",
    "fnbr = fnbr.groupby(\"idFrame\")[\"name_x\"].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the FrameNet+ dict to filter out frames from the main DataFrame. We want to make sure that we only consider frames that exist in FrameNet+ for the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = frames[frames['idFrame'].isin(fnp)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build FrameNet graph based on frame relations. This data will be used to find child frames when generating some prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "inheritances = frame_relations[frame_relations[\"entry\"] == \"rel_inheritance\"]\n",
    "\n",
    "frame_network = nx.DiGraph()\n",
    "frame_network.add_nodes_from(\n",
    "    pd.concat([inheritances['idFrame1'], inheritances['idFrame2']]).unique())\n",
    "frame_network.add_edges_from(\n",
    "    [(j, i) for i, j in zip(inheritances['idFrame1'], inheritances['idFrame2'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def clean_def(text):\n",
    "    \"\"\"\n",
    "    Cleans the definitions of frames and FEs of XML tags.\n",
    "    A lot of times, XML tags are used to designate where the text refers to the actual definition\n",
    "    or some example sentences.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'\\<ex\\>.*', '', text, flags=re.DOTALL)\n",
    "    text = text.replace('<def-root>', '')\n",
    "    text = text.replace('</def-root>', '')\n",
    "    def_root = ET.fromstring('<def>' + text + '</def>')\n",
    "    def_str = def_root.text if def_root.text is not None else \"\"\n",
    "    for child in def_root:\n",
    "        if child.tag == \"ex\":\n",
    "            break\n",
    "        if child.text is not None:\n",
    "            def_str += child.text\n",
    "        if child.tail is not None:\n",
    "            def_str += child.tail\n",
    "\n",
    "    return def_str.strip()\n",
    "\n",
    "# Remove XML tags used to refer to frame elements in frame and FE definitions\n",
    "frames[\"description\"] = frames[\"description\"].apply(clean_def)\n",
    "fes[\"description\"] = fes[\"description\"].apply(clean_def)\n",
    "# Remove redundant spaces and \"#\", sometimes used to refer to frame elements\n",
    "frames[\"description\"] = frames[\"description\"].str.replace('\\s+', r' ', regex=True)\n",
    "frames[\"description\"] = frames[\"description\"].str.replace('#(\\w+)', r'\\1', regex=True)\n",
    "fes[\"description\"] = fes[\"description\"].str.replace('\\s+', r' ', regex=True)\n",
    "fes[\"description\"] = fes[\"description\"].str.replace('#(\\w+)', r'\\1', regex=True)\n",
    "\n",
    "# Stripping and removing \"FN: \" from LU sense descriptions\n",
    "lus_en[\"senseDescription\"] = lus_en[\"senseDescription\"].str.replace('FN: ', '')\n",
    "lus_en[\"senseDescription\"] = lus_en[\"senseDescription\"].str.strip()\n",
    "lus_pt[\"senseDescription\"] = lus_pt[\"senseDescription\"].str.replace('FN: ', '')\n",
    "lus_pt[\"senseDescription\"] = lus_pt[\"senseDescription\"].str.strip()\n",
    "# Removing other symbols that we don't want on prompts (e.g. underscores instead of spaces in LU names)\n",
    "lus_en[\"name\"] = lus_en[\"name\"].str.replace('_', ' ')\n",
    "lus_en[\"name\"] = lus_en[\"name\"].str.replace('[', '(', regex=False)\n",
    "lus_en[\"name\"] = lus_en[\"name\"].str.replace(']', ')', regex=False)\n",
    "lus_pt[\"name\"] = lus_pt[\"name\"].str.replace('_', ' ')\n",
    "lus_pt[\"name\"] = lus_pt[\"name\"].str.replace('[', '(', regex=False)\n",
    "lus_pt[\"name\"] = lus_pt[\"name\"].str.replace(']', ')', regex=False)\n",
    "\n",
    "# Strip frame names\n",
    "frames['name'] = frames['name'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample FrameNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we split frames into four different DataFrames based on their \"type\". Events, entities and attributes are already indicated in FrameNet Brasil's database. For artifacts we do it manually, following the inheritance tree of the Artifcat frame (id: 390)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_child(frame_id, network):\n",
    "    \"\"\"\n",
    "    Recursively iterates over the frame network to find all\n",
    "    child frames of a given frame and returns them as a set.\n",
    "    \"\"\"\n",
    "    child = set()\n",
    "    \n",
    "    for pred in network.predecessors(frame_id):\n",
    "        child.add(pred)\n",
    "        child.update(find_child(pred, network))\n",
    "    \n",
    "    return child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "frm_event = set(frames[frames['frameTop'] == 'frm_event']['idFrame'])\n",
    "frm_entity = set(frames[frames['frameTop'] == 'frm_entity']['idFrame'])\n",
    "frm_attribute = set(frames[frames['frameTop'] == 'frm_attributes']['idFrame'])\n",
    "\n",
    "frm_artifact = find_child(390, frame_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we find the FE and LU count of each frame..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_fes = fes[fes['typeEntry'].isin(['cty_core', 'cty_core-unexpressed'])]\n",
    "\n",
    "fe_count = core_fes.groupby('idFrame').count()['idFrameElement']\n",
    "lu_count = lus_en.groupby('idFrame').count()['idLU']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and split them into different scenarios based on LU and FE counts. Here we have 4 scenarios based on the combination of low vs. high counts on FEs and LUs. Each frame type has its own splits, so we end up with 16 scenarios (of which 12 were reported in our Element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splits_by_scenario(frames, fe_count, lu_count):\n",
    "    \"\"\"\n",
    "    This function takes a frame set and the global FE and\n",
    "    LU counts and returns a 4-tuple containing lists of frame ids.\n",
    "    Each list containts the frames that belong to that split/scenario.\n",
    "    \"\"\"\n",
    "    fe_count = fe_count[fe_count.index.isin(frames)]\n",
    "    lu_count = lu_count[lu_count.index.isin(frames)]\n",
    "    \n",
    "    lower_fe = fe_count[fe_count <= fe_count.quantile(.25)]\n",
    "    upper_fe = fe_count[fe_count >= fe_count.quantile(.75)]\n",
    "    \n",
    "    lower_lu = lu_count[lu_count <= lu_count.quantile(.25)]\n",
    "    upper_lu = lu_count[lu_count >= lu_count.quantile(.75)]\n",
    "    \n",
    "    return (\n",
    "        lower_fe.index.intersection(lower_lu.index),\n",
    "        lower_fe.index.intersection(upper_lu.index),\n",
    "        upper_fe.index.intersection(lower_lu.index),\n",
    "        upper_fe.index.intersection(upper_lu.index)\n",
    "    )\n",
    "\n",
    "event_splits = get_splits_by_scenario(frm_event, fe_count, lu_count)\n",
    "entity_splits = get_splits_by_scenario(frm_entity, fe_count, lu_count)\n",
    "attribute_splits = get_splits_by_scenario(frm_attribute, fe_count, lu_count)\n",
    "artifact_splits = get_splits_by_scenario(frm_artifact, fe_count, lu_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the utility functions used by the prompt generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from random import random\n",
    "from collections import OrderedDict\n",
    "from networkx import all_neighbors\n",
    "\n",
    "POS = {\n",
    "    \"v\": \"verb\",\n",
    "    \"a\": \"adjective\",\n",
    "    \"n\": \"noun\",\n",
    "    \"adv\": \"adverb\",\n",
    "    \"pron\": \"pronoun\",\n",
    "    \"prep\": \"preposition\",\n",
    "    \"idio\": \"idiomatic expression\"\n",
    "}\n",
    "\n",
    "def get_prompt_data(idFrame):\n",
    "    \"\"\"\n",
    "    Gets all the data required to build prompts for a given frame.\n",
    "    \"\"\"\n",
    "    frm = frames.loc[idFrame]\n",
    "    core_fes = fes[(fes[\"idFrame\"] == idFrame) & (fes[\"typeEntry\"] == \"cty_core\")]\n",
    "    unexp_fes = fes[(fes[\"idFrame\"] == idFrame) & (fes[\"typeEntry\"] == \"cty_core-unexpressed\")]\n",
    "    lus = lus_en[lus_en[\"idFrame\"] == idFrame]\n",
    "    \n",
    "    core_fes = core_fes[[\"name\", \"description\"]].to_dict('records')\n",
    "    unexp_fes = unexp_fes[[\"name\", \"description\"]].to_dict('records')\n",
    "    lus = lus[[\"name\", \"senseDescription\"]].to_dict('records')\n",
    "    \n",
    "    return {\n",
    "        \"id\": frm[\"idFrame\"],\n",
    "        \"name\": frm[\"name\"],\n",
    "        \"description\": frm[\"description\"],\n",
    "        \"core_fes\": core_fes,\n",
    "        \"unexp_fes\": unexp_fes,\n",
    "        \"lus\": lus\n",
    "    }\n",
    "\n",
    "\n",
    "def fmt_entity(text):\n",
    "    return text.replace('_', ' ')\n",
    "\n",
    "def fmt_definition(text):\n",
    "    return text.strip()[:-1] if text.strip()[-1] == '.' else text\n",
    "\n",
    "def build_comma_string(arr):\n",
    "    \"\"\"\n",
    "    Builds a string with commas and \"and\" of the array elements\n",
    "    \"\"\"\n",
    "    if len(arr) == 1:\n",
    "        return f'\"{fmt_entity(arr[0])}\"'\n",
    "    \n",
    "    if len(arr) == 2:\n",
    "        return f'\"{fmt_entity(arr[0])}\" and \"{fmt_entity(arr[-1])}\"'\n",
    "    \n",
    "    other = ''.join([f', \"{fmt_entity(w)}\"' for w in arr[1:-1]])\n",
    "\n",
    "    return f'\"{fmt_entity(arr[0])}\"{other} and \"{fmt_entity(arr[-1])}\"'\n",
    "\n",
    "\n",
    "def count_pos(lus):\n",
    "    \"\"\"\n",
    "    Counts the number of POS occurences in the LU set\n",
    "    \"\"\"\n",
    "    counts = OrderedDict()\n",
    "    \n",
    "    for lu in lus:\n",
    "        pos = lu[1]\n",
    "        if pos in counts:\n",
    "            counts[pos] += 1\n",
    "        else:\n",
    "            counts[pos] = 1\n",
    "    \n",
    "    return counts\n",
    "\n",
    "\n",
    "def get_pos_names(counts):\n",
    "    \"\"\"\n",
    "    Gets the POS names based on their counts, i.e.,\n",
    "    turns them into plurals when necessary\n",
    "    \"\"\"\n",
    "    pos_dict = POS.copy()\n",
    "    \n",
    "    for k, v in counts.items():\n",
    "        if v > 1:\n",
    "            # add plural\n",
    "            pos_dict[k] += 's'\n",
    "            \n",
    "    return pos_dict\n",
    "\n",
    "\n",
    "def build_fe_text(core_fes, unexp_fes = []):\n",
    "    \"\"\"\n",
    "    Builds the basic FE text used in all prompts.\n",
    "    \"\"\"\n",
    "    core_fes = [f[\"name\"] for f in core_fes]\n",
    "    unexp_fes = [f[\"name\"] for f in unexp_fes]\n",
    "    \n",
    "    prompt = ''\n",
    "    \n",
    "    if len(core_fes) == 1:\n",
    "        prompt += f' The core frame element in this frame is \"{fmt_entity(core_fes[0])}\".'\n",
    "    else:\n",
    "        prompt += f' Core frame elements in this frame are {to_comma(core_fes)}.'\n",
    "    \n",
    "    if len(unexp_fes) == 1:\n",
    "        prompt += f' The core unexpressed frame element in this frame is \"{fmt_entity(unexp_fes[0])}\".'\n",
    "    elif len(unexp_fes) > 1:\n",
    "        prompt += f' Core unexpressed frame elements in this frame are {to_comma(unexp_fes)}.'\n",
    "        \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def build_lu_text(lus):\n",
    "    \"\"\"\n",
    "    Builds the basic LU text used in all prompts.\n",
    "    \"\"\"\n",
    "    lus = sorted((lu[\"name\"].split('.') for lu in lus), key=lambda lu: lu[1])\n",
    "    \n",
    "    if len(lus) == 1:\n",
    "        return f' This frame is evoked by the {POS[lus[0][1]]} \"{lus[0][0]}\"'\n",
    "    else:\n",
    "        pos = lus[0][1]\n",
    "        pos_i = 1\n",
    "        counts = count_pos(lus)\n",
    "        names = pos_names(counts)\n",
    "        order = list(counts.keys())\n",
    "        text = f' Words evoking this frame are the {names[pos]} \"{lus[0][0]}\"'\n",
    "        \n",
    "        for i, lu in enumerate(lus[1:]):\n",
    "            if lu[1] == pos:\n",
    "                pos_i += 1\n",
    "                last = i+2 == len(lus) or pos_i == counts[pos]\n",
    "                sep = ' and' if last else ','\n",
    "                text += f'{sep} \"{lu[0]}\"'\n",
    "            else:\n",
    "                pos = lu[1]\n",
    "                pos_i = 0\n",
    "                sep = ' and' if pos == order[-1] else ','\n",
    "                text += f'{sep} the {names[pos]} \"{lu[0]}\"'\n",
    "        \n",
    "        return text + '.'\n",
    "\n",
    "\n",
    "def get_random_child(frame_id, network):\n",
    "    \"\"\"\n",
    "    Gets a random child frame of the given frame_id\n",
    "    \"\"\"\n",
    "    options = list(network.predecessors(frame_id))\n",
    "    return options[math.floor(random() * len(options))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions used to build different types of prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def prompt_suggest_lus(data):\n",
    "    \"\"\"\n",
    "    Builds a prompt that asks the assistant to propose new LUs.\n",
    "    \"\"\"\n",
    "    # Frame definition\n",
    "    prompt = f'The semantic frame for \"{fmt_entity(data[\"name\"])}\" is defined as follows:'\n",
    "    prompt += f' \"{fmt_definition(data[\"description\"])}\".'\n",
    "    \n",
    "    # FEs\n",
    "    prompt += fe_text(data[\"core_fes\"], data[\"unexp_fes\"])\n",
    "    \n",
    "    # FE definitions\n",
    "    for fe in data[\"core_fes\"]:\n",
    "        prompt += f' {fmt_definition(fe[\"name\"])}: {fmt_definition(fe[\"description\"])}.'\n",
    "    for fe in data[\"unexp_fes\"]:\n",
    "        prompt += f' {fmt_definition(fe[\"name\"])}: {fmt_definition(fe[\"description\"])}.'\n",
    "        \n",
    "    # LU\n",
    "    prompt += lu_text(data[\"lus\"])\n",
    "    \n",
    "    # Request part\n",
    "    prompt += f' Please propose 10 additional words that evoke the \"{fmt_entity(data[\"name\"])}\" semantic frame.'\n",
    "    prompt += f' Present them as a JSON array.'\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def prompt_create_from_lus(data, new_lus):\n",
    "    \"\"\"\n",
    "    Builds a prompt that asks the assistant to create a new subframe\n",
    "    of the given frame based on a set of LUs that the new frame must evoke.\n",
    "    \"\"\"\n",
    "    # Frame definition\n",
    "    prompt = f'The semantic frame for \"{fmt_entity(data[\"name\"])}\" is defined as follows:'\n",
    "    prompt += f' \"{fmt_definition(data[\"description\"])}\".'\n",
    "    \n",
    "    # FEs\n",
    "    fes = [f[\"name\"] for f in data[\"core_fes\"]]\n",
    "    \n",
    "    if len(fes) == 1:\n",
    "        prompt += f' The semantic frame for \"{fmt_entity(data[\"name\"])}\" has one core frame element:'\n",
    "        prompt += f' \"{fmt_entity(fes[0])}\".'\n",
    "    else:\n",
    "        prompt += f' The semantic frame for \"{fmt_entity(data[\"name\"])}\" has {len(fes)} core elements:'\n",
    "        prompt += f' {to_comma(fes)}.'\n",
    "\n",
    "    for fe in data[\"core_fes\"]:\n",
    "        prompt += f' The definition of the \"{fmt_entity(fe[\"name\"])}\" frame element is as follows:'\n",
    "        prompt += f' \"{fmt_definition(fe[\"description\"])}\".'\n",
    "\n",
    "    # LUs\n",
    "    prompt += lu_text(data[\"lus\"])\n",
    "    \n",
    "    # Request part\n",
    "    prompt += f' First, propose a semantic frame evoked by words such as {to_comma(new_lus)}.'\n",
    "    prompt += f' Second, please propose semantic frames for other kinds of \"{fmt_entity(data[\"name\"])}\".'\n",
    "    prompt += ' Present them as table in which columns are \"Frame Name\", \"Frame Definition\", \"Frame Elements\", \"Frame Element Definition\" and \"Words evoking the frame\".'\n",
    "        \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def prompt_create_from_inheritance(data, child_data):\n",
    "    \"\"\"\n",
    "    Builds a prompt that asks the assistant to propose subframes of\n",
    "    the given frame.\n",
    "    \"\"\"\n",
    "    # Frame definition\n",
    "    prompt = f'There is a semantic frame for \"{fmt_entity(data[\"name\"])}\", whose definition is as follows:'\n",
    "    prompt += f' \"{fmt_definition(data[\"description\"])}\".'\n",
    "    \n",
    "    # FEs\n",
    "    prompt += fe_text(data[\"core_fes\"], data[\"unexp_fes\"])\n",
    "    \n",
    "    # Child frame\n",
    "    prompt += f' The \"{fmt_entity(child_data[\"name\"])}\" frame inherits the \"{fmt_entity(data[\"name\"])}\" frame.'\n",
    "    \n",
    "    # Child FEs\n",
    "    prompt += fe_text(data[\"core_fes\"])\n",
    "    \n",
    "    # Child LUs\n",
    "    prompt += lu_text(child_data[\"lus\"])\n",
    "    \n",
    "    # Request part\n",
    "    prompt += f' Please propose other semantic frames inheriting the \"{fmt_entity(data[\"name\"])}\" frame.'\n",
    "    prompt += ' Present them as a table in which columns are \"Frame Name\", \"Frame Definition\", \"Frame Elements\", \"Frame Element Definition\" and \"Words evoking the frame\".'\n",
    "        \n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small test..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idFrame</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>frameTop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idFrame</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>226</td>\n",
       "      <td>Entity</td>\n",
       "      <td>This frame is for words that denote highly sch...</td>\n",
       "      <td>frm_entity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         idFrame    name                                        description  \\\n",
       "idFrame                                                                       \n",
       "226          226  Entity  This frame is for words that denote highly sch...   \n",
       "\n",
       "           frameTop  \n",
       "idFrame              \n",
       "226      frm_entity  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames[frames[\"name\"] == \"Entity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The semantic frame for \"Entity\" is defined as follows: \"This frame is for words that denote highly schematic entities\". The semantic frame for \"Entity\" has one core frame element: \"Entity\". The definition of the \"Entity\" frame element is as follows: \"A thing (either abstract or physical) that exists with some degree of permanence\". Words evoking this frame are the adverb \"anything\", the nouns \"item\", \"entity\", \"object\", \"thing\", \"individual\", \"what\", \"material\", \"something\", \"article\", \"stuff\", \"paradox\", \"page\", \"plate\", \"rainbow\", \"trash\", \"waste\", \"label\", \"resource\", \"fuse\", \"grocery\" and the pronoun \"everything\". First, propose a semantic frame evoked by words such as \"god\", \"saint\", \"deity\" and \"goddess\". Second, please propose semantic frames for other kinds of \"Entity\". Present them as table in which columns are \"Frame Name\", \"Frame Definition\", \"Frame Elements\", \"Frame Element Definition\" and \"Words evoking the frame\".\n"
     ]
    }
   ],
   "source": [
    "print(prompt_create_from_lus(get_prompt_data(226), [\"god\", \"saint\", \"deity\", \"goddess\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idFrame</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>frameTop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idFrame</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>178</td>\n",
       "      <td>Intentionally_act</td>\n",
       "      <td>This is an abstract frame for acts performed b...</td>\n",
       "      <td>frm_event</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         idFrame               name  \\\n",
       "idFrame                               \n",
       "178          178  Intentionally_act   \n",
       "\n",
       "                                               description   frameTop  \n",
       "idFrame                                                                \n",
       "178      This is an abstract frame for acts performed b...  frm_event  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames[frames[\"name\"] == \"Intentionally_act\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child = get_prompt_data(get_random_child(178, frame_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idFrame                                                      783\n",
       "name                                                Execute_plan\n",
       "description    An Agent acts according to a Plan, carrying it...\n",
       "frameTop                                               frm_event\n",
       "Name: 783, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames.loc[child[\"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a semantic frame for \"Intentionally act\", whose definition is as follows: \"This is an abstract frame for acts performed by sentient beings\". The core frame element in this frame is \"Agent\". The core unexpressed frame element in this frame is \"Act\". The \"Execute plan\" frame inherits the \"Intentionally act\" frame. The core frame element in this frame is \"Agent\". Words evoking this frame are the nouns \"implementation\", \"effect (into effect)\" and \"force (into force)\" and the verbs \"implement\" and \"institute\". Please propose other semantic frames inheriting the \"Intentionally act\" frame. Present them as a table in which columns are \"Frame Name\", \"Frame Definition\", \"Frame Elements\", \"Frame Element Definition\" and \"Words evoking the frame\".\n"
     ]
    }
   ],
   "source": [
    "print(prompt_create_from_inheritance(get_prompt_data(178), child))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate full experiment file (assistant suggest new files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_split_prompt(splits, random=True, size=5):\n",
    "    \"\"\"\n",
    "    Generates all prompts asking the assistant to suggest new LUs.\n",
    "    These are organized into different splits and returned as a single string.\n",
    "    \"\"\"\n",
    "    full_prompt = ''\n",
    "    \n",
    "    for i, split in enumerate(splits):\n",
    "        full_prompt += \"=================================================\\n\"\n",
    "        full_prompt += f'---------------      SPLIT {i}      ---------------\\n'\n",
    "        full_prompt += \"=================================================\\n\"\n",
    "        \n",
    "        if random:\n",
    "            frame_ids = np.random.choice(split, size=size, replace=False)\n",
    "        else:\n",
    "            frame_ids = split\n",
    "        \n",
    "        for idFrame in frame_ids:\n",
    "            full_prompt += f'{str(idFrame)} - {prompt_suggest_lus(get_prompt_data(idFrame))}'\n",
    "            full_prompt += '\\n\\n\\n'\n",
    "\n",
    "    return full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_prompts \u001b[38;5;241m=\u001b[39m generate_split_prompt(entity_splits)\n",
      "Cell \u001b[0;32mIn[113], line 16\u001b[0m, in \u001b[0;36mgenerate_split_prompt\u001b[0;34m(splits, random, size)\u001b[0m\n\u001b[1;32m     13\u001b[0m full_prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=================================================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m random:\n\u001b[0;32m---> 16\u001b[0m     frame_ids \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(split, size\u001b[38;5;241m=\u001b[39msize, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     frame_ids \u001b[38;5;241m=\u001b[39m split\n",
      "File \u001b[0;32mmtrand.pyx:1000\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "all_prompts = generate_split_prompt(entity_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the compiled responses we got from ChatGPT and OpenAssistant to evaluate their LU suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "ASSISTANT = \"ChatGPT\" # OpenAssistant\n",
    "LANG = \"en\" # or pt\n",
    "\n",
    "with open(os.path.join(ASSISTANT, f'event_{LANG}.json')) as fp:\n",
    "    event_lus = json.load(fp)\n",
    "    \n",
    "with open(os.path.join(ASSISTANT, f'entity_{LANG}.json')) as fp:\n",
    "    entity_lus = json.load(fp)\n",
    "    \n",
    "with open(os.path.join(ASSISTANT, f'attribute_{LANG}.json')) as fp:\n",
    "    attribute_lus = json.load(fp)\n",
    "    \n",
    "# with open(os.path.join(ASSISTANT, f'artifact_{LANG}.json')) as fp:\n",
    "#     artifact_lus = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(type_lus):\n",
    "    return pd.DataFrame.from_records([\n",
    "        { \"idFrame\": int(idFrame), \"lu\": clean_lu(lu), \"split\": split }\n",
    "        for split, frames in type_lus.items()\n",
    "        for idFrame, lus in frames.items()\n",
    "        for lu in lus\n",
    "    ])\n",
    "\n",
    "\n",
    "def is_in_fn_plus(row, dataset):\n",
    "    frame_id = row[\"idFrame\"]\n",
    "    return frame_id in fn_plus and row[\"lu\"] in fn_plus[frame_id]\n",
    "\n",
    "def is_in_fnbr(row, dataset):\n",
    "    frame_id = row[\"idFrame\"]\n",
    "    return frame_id in fnbr and row[\"lu\"] in fnbr[frame_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_df(artifact_lus)\n",
    "\n",
    "df['split'] = df['split'].str.replace('split-', '')\n",
    "\n",
    "if LANG == \"en\":\n",
    "    df['FN+?'] = df.apply(is_in_fn_plus, axis='columns')\n",
    "else:\n",
    "    df['FN-Br?'] = df.apply(is_in_fnbr, axis='columns')\n",
    "\n",
    "df = df.merge(df_frm.reset_index(drop=True), on='idFrame')\n",
    "\n",
    "df[['name', 'lu', 'split', 'FN+?']].to_csv('lus.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
